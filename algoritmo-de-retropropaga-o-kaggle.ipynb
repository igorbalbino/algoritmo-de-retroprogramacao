{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":10450,"sourceType":"datasetVersion","datasetId":7317}],"dockerImageVersionId":30664,"isInternetEnabled":false,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-20T12:07:51.060646Z","iopub.execute_input":"2024-03-20T12:07:51.061135Z","iopub.status.idle":"2024-03-20T12:07:51.074328Z","shell.execute_reply.started":"2024-03-20T12:07:51.061102Z","shell.execute_reply":"2024-03-20T12:07:51.073368Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/data_banknote_authentication/data_banknote_authentication.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn import preprocessing as pre\nimport time\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nprint('done!')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T12:09:41.026116Z","iopub.execute_input":"2024-03-20T12:09:41.026619Z","iopub.status.idle":"2024-03-20T12:09:41.185329Z","shell.execute_reply.started":"2024-03-20T12:09:41.026577Z","shell.execute_reply":"2024-03-20T12:09:41.183821Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"done!\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\nhttps://archive.ics.uci.edu/datasets\n'''\nstart_time = time.time()\ndataset = shuffle(pd.read_csv('/kaggle/input/data_banknote_authentication/data_banknote_authentication.csv'))\ndataset.head()","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# mudando nome das colunas que vieram desformatadas\ndataset.columns = ['Variance of Wavelet Transformed Image', 'Skewness of Wavelet Transformed Image', \n                   'Curtosis of Wavelet Transformed Image', 'Entropy of Image', 'Class']\n\n# mudando valores da coluna Class para que 1 seja 0 e -1 seja 1\n#dataset.loc[dataset['Class'] == 1, 'Class'] = -1\n#dataset.loc[dataset['Class'] == 0, 'Class'] = 1\n\nx = dataset[['Variance of Wavelet Transformed Image', 'Skewness of Wavelet Transformed Image', 'Curtosis of Wavelet Transformed Image', 'Entropy of Image']]\ny = dataset[['Class']]\n\ndataset.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-20T12:25:39.355319Z","iopub.execute_input":"2024-03-20T12:25:39.355954Z","iopub.status.idle":"2024-03-20T12:25:39.380377Z","shell.execute_reply.started":"2024-03-20T12:25:39.355900Z","shell.execute_reply":"2024-03-20T12:25:39.378999Z"},"trusted":true},"execution_count":6,"outputs":[{"execution_count":6,"output_type":"execute_result","data":{"text/plain":"      Variance of Wavelet Transformed Image  \\\n232                                 0.46901   \n268                                 4.93420   \n1131                               -3.38840   \n858                                -5.87300   \n22                                  0.93584   \n\n      Skewness of Wavelet Transformed Image  \\\n232                                -0.63321   \n268                                 2.41070   \n1131                               -8.21500   \n858                                 9.17520   \n22                                  8.88550   \n\n      Curtosis of Wavelet Transformed Image  Entropy of Image  Class  \n232                                 7.38480           0.36507     -1  \n268                                -0.17594           1.62450     -1  \n1131                               10.33150           0.98187     -1  \n858                                -0.27448          -6.04220     -1  \n22                                 -1.68310          -1.65990     -1  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Variance of Wavelet Transformed Image</th>\n      <th>Skewness of Wavelet Transformed Image</th>\n      <th>Curtosis of Wavelet Transformed Image</th>\n      <th>Entropy of Image</th>\n      <th>Class</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>232</th>\n      <td>0.46901</td>\n      <td>-0.63321</td>\n      <td>7.38480</td>\n      <td>0.36507</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>268</th>\n      <td>4.93420</td>\n      <td>2.41070</td>\n      <td>-0.17594</td>\n      <td>1.62450</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>1131</th>\n      <td>-3.38840</td>\n      <td>-8.21500</td>\n      <td>10.33150</td>\n      <td>0.98187</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>858</th>\n      <td>-5.87300</td>\n      <td>9.17520</td>\n      <td>-0.27448</td>\n      <td>-6.04220</td>\n      <td>-1</td>\n    </tr>\n    <tr>\n      <th>22</th>\n      <td>0.93584</td>\n      <td>8.88550</td>\n      <td>-1.68310</td>\n      <td>-1.65990</td>\n      <td>-1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"# separando dados\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=4)\nprint('done!')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T12:30:49.257448Z","iopub.execute_input":"2024-03-20T12:30:49.257927Z","iopub.status.idle":"2024-03-20T12:30:49.269616Z","shell.execute_reply.started":"2024-03-20T12:30:49.257892Z","shell.execute_reply":"2024-03-20T12:30:49.268272Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"done!\n","output_type":"stream"}]},{"cell_type":"code","source":"# normaliza os dados\nx_train = pre.StandardScaler().fit_transform(x_train)\nx_test = pre.StandardScaler().fit_transform(x_test)\n\n# transforma em array do numpy\ny_train = y_train.to_numpy()\ny_test = y_test.to_numpy()\n\nend_time = time.time()\ntotal_time = end_time - start_time\n\nprint('Time for preprocessing: %f seconds \\n' % total_time)\nx_train","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# hyperbolic tangent activation func\ndef hyperbolic_tanh(x):\n    return (np.exp(x) - np.exp(x)) / (np.exp(x) + np.exp(x))\n\n#hyperbolic derivative\ndef derivative_hyperbolic(x):\n    return 1 - hyperbolic_tanh(x) * hyperbolic_tanh(x)\n\nprint('done!')","metadata":{"execution":{"iopub.status.busy":"2024-03-20T12:34:49.160450Z","iopub.execute_input":"2024-03-20T12:34:49.160917Z","iopub.status.idle":"2024-03-20T12:34:49.168673Z","shell.execute_reply.started":"2024-03-20T12:34:49.160882Z","shell.execute_reply":"2024-03-20T12:34:49.167316Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"done!\n","output_type":"stream"}]},{"cell_type":"code","source":"# init hyperparameter\nprint('----- Initializing Hyperparameter -----')\nstart_time = time.time()\n\n#setting hyperparameter\n'''\nparametros de treinamento. não explicou por que dos valores, só colocou ali\n'''\nnp.random.seed(10) # original é 10. mudei pra 20 mas não alterou a acuracia\ninp = 4 # número de neurônios na camada de entrada # essa variavel está diretamente ligada com a celula abaixo. \n# mudando para cima, da problema na linha `l1 = np.dot(x_train, w1_l1)`\n# mudei o random_state do train_test_split para 0 e 1 sem mudar o inp e tudo correu normal, mas a acuracia diminuiu para 55%\nhd = 6 # número de neurônios nas camadas ocultas # original do tutorial é 6. mudei para 5 e 4 mas não alterou a acuracia\nout = 1 # número de neurônios na camada de saída\n\nactual_out_size = y_train.size\nepochs = 5000 # original do tutorial é 10000\neta = 0.001 # taxa de aprendizado # original é 0.001. mudei para 0.002 mas não alterou a acuracia\nalpha = 0.5 # parâmetro de regularização # original é 0.7. mudei para 0.5 mas não alterou a acuracia\n\nprint('----- Setting 4 weights for hidden levels -----')\n'''\npesos iniciais definidos para as camadas ocultas\n'''\nw1_l1 = np.random.randn(inp, hd)\nw2_l2 = np.random.randn(hd, hd)\nw3_l3 = np.random.randn(hd, hd)\nw4_l4 = np.random.randn(hd, hd)\nout_w = np.random.randn(hd, out)\n\nacc_list =  []\n\nend_time = time.time()\ntotal_time = end_time - start_time\n\nprint('Time for setting parameter: %f seconds \\n' % total_time)\n\n'''\nEXPLICAÇÃO GEMINI - GOOGLE\n\n1. Inicialização de Hiperparâmetros:\nA primeira parte do código define e inicializa os hiperparâmetros da rede neural.\nA semente aleatória é fixada em 10 (ou 20, conforme sua modificação) para garantir a reprodutibilidade dos resultados.\nO número de neurônios na camada de entrada (inp) é definido como 4.\nO número de neurônios nas camadas ocultas (hd) é definido como 6 (ou 5 ou 4, conforme sua modificação).\nO número de neurônios na camada de saída (out) é definido como 1.\nO número de épocas de treinamento (epochs) é definido como 5000 (ou 10000 no tutorial original).\nA taxa de aprendizado (eta) é definida como 0.001 (ou 0.002, conforme sua modificação).\nO parâmetro de regularização (alpha) é definido como 0.5 (ou 0.7 no tutorial original).\n\n2. Definição dos Pesos Iniciais:\nA próxima parte do código define os pesos iniciais para as camadas ocultas da rede neural.\nOs pesos são inicializados aleatoriamente usando a função np.random.randn.\n\n\n--------------------------------------------------------------------------------\n\n\n1. Número de Neurônios na Camada de Entrada:\nDefine a dimensionalidade da entrada da rede neural.\nDeve ser igual ao número de features do seu conjunto de dados.\nPor exemplo, se o seu conjunto de dados possui imagens de 28x28 pixels, a camada de entrada terá 784 neurônios (28 x 28).\n\n2. Número de Neurônios nas Camadas Ocultas:\nDefine a capacidade da rede neural de aprender relações complexas entre as features.\nMais neurônios permitem que a rede aprenda representações mais complexas, mas também aumentam a complexidade da rede e o risco de overfitting.\nO número ideal de neurônios nas camadas ocultas é geralmente encontrado por experimentação.\n\n3. Número de Neurônios na Camada de Saída:\nDefine o número de classes que a rede neural pode classificar.\nSe você tem um problema de classificação binária, a camada de saída terá 1 neurônio.\nSe você tem um problema de classificação multiclasse, a camada de saída terá um neurônio para cada classe.\n\n4. Taxa de Aprendizado:\nControla a rapidez com que os pesos da rede neural são atualizados durante o treinamento.\nUma taxa de aprendizado alta faz com que a rede aprenda mais rapidamente, mas também pode levar a instabilidade e overfitting.\nUma taxa de aprendizado baixa faz com que a rede aprenda mais lentamente, mas pode ser mais estável e levar a um melhor desempenho.\n\n5. Parâmetro de Regularização:\nControla a quantidade de regularização aplicada à rede neural.\nA regularização ajuda a prevenir overfitting, penalizando pesos grandes.\nUm valor alto de regularização pode levar a underfitting, enquanto um valor baixo pode levar a overfitting.\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-20T12:42:58.097989Z","iopub.execute_input":"2024-03-20T12:42:58.098492Z","iopub.status.idle":"2024-03-20T12:42:58.110440Z","shell.execute_reply.started":"2024-03-20T12:42:58.098453Z","shell.execute_reply":"2024-03-20T12:42:58.109116Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"----- Initializing Hyperparameter -----\n----- Setting 4 weights for hidden levels -----\nTime for setting parameter: 0.001018 seconds \n\n","output_type":"stream"}]},{"cell_type":"code","source":"# traning backpropagation algh\nprint('----- Traning Backpropagation Algorithm -----')\nstart_time = time.time()\n\n# criterio de parada do Backpropagation é o número de epocas que definimos anteriormente\nfor i in range(epochs):\n    # feedforward for 4 hidden layers by calling activation func\n    l1 = np.dot(x_train, w1_l1)\n    l1_out = hyperbolic_tanh(l1)\n    \n    l2 = np.dot(l1_out, w2_l2)\n    l2_out = hyperbolic_tanh(l2)\n    \n    l3 = np.dot(l2_out, w3_l3)\n    l3_out = hyperbolic_tanh(l3)\n    \n    l4 = np.dot(l3_out, w4_l4)\n    l4_out = hyperbolic_tanh(l4)\n    \n    output = np.dot(l4_out, out_w)\n    final_out = hyperbolic_tanh(output)\n    '''\n    o bloco acima olha a saída de cada nivel e peso e repropagando o erro para calcular o \n    peso de cada camada\n    '''\n    \n    #calcula acuracia\n    final_out = final_out.round()\n    calc_acc = (final_out == y_train).sum()\n    acc = calc_acc / actual_out_size\n    acc_list.append(acc)\n    '''\n    o bloco acima calcula o quanto o modelo acertou\n    '''\n    \n    #backpropagation for 4 hidden layers\n    final_err = final_out - y_train\n    final_signoid_derivative = final_err * derivative_hyperbolic(final_out)\n    \n    l4_err = np.dot(final_signoid_derivative, out_w.T)\n    l4_derivative = l4_err *derivative_hyperbolic(l4_out)\n    \n    l3_err = np.dot(final_signoid_derivative, out_w.T)\n    l3_derivative = l3_err *derivative_hyperbolic(l3_out)\n    \n    l2_err = np.dot(final_signoid_derivative, out_w.T)\n    l2_derivative = l2_err *derivative_hyperbolic(l2_out)\n    \n    l1_err = np.dot(final_signoid_derivative, out_w.T)\n    l1_derivative = l1_err *derivative_hyperbolic(l1_out)\n    \n    # divide peso do nivel por tamanho da saída\n    output_weights = np.dot(l4_out.T, final_signoid_derivative) / actual_out_size\n    wheight4 = np.dot(l3_out.T, l4_derivative) / actual_out_size\n    wheight3 = np.dot(l2_out.T, l3_derivative) / actual_out_size\n    wheight2 = np.dot(l1_out.T, l2_derivative) / actual_out_size\n    wheight1 = np.dot(x_train.T, l1_derivative) / actual_out_size\n    '''\n    divide os pesos por cada saída \n    '''\n    \n    out_w -= eta * alpha * output_weights\n    w4_l4 -= eta * alpha * wheight4\n    w3_l3 -= eta * alpha * wheight3\n    w2_l2 -= eta * alpha * wheight2\n    w1_l1 -= eta * alpha * wheight1\n    '''\n    multiplica os pesos pelas taxas de aprendizado e refaz o processo até que atinja \n    o criterio de parada\n    '''\n\nprint('Traning accuracy: ' + str(round(acc_list[-1], 2) * 100) + ' %')\nend_time = time.time()\ntotal_time = end_time - start_time\nprint('Time traning algorithm: %f seconds \\n' % total_time)\n\nprint('----- Plotting Accuracy Curve -----')\nplt.title('Accuracy Curve')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.plot(acc_list)\nplt.show()\n\n\n'''\nEXPLICAÇÃO GEMINI - GOOGLE\n\n1. Processo de Propagação (Feedforward):\nO código itera por um número definido de épocas (epochs).\nEm cada época, ele propaga a entrada (x_train) através da rede neural.\nPara cada camada oculta (l1, l2, l3, l4), o código realiza:\nCálculo da saída ponderada usando multiplicação de matriz (np.dot) entre a entrada da camada e os pesos correspondentes (w1_l1, w2_l2, etc.).\nAplicação da função de ativação tangente hiperbólica (hyperbolic_tanh) para introduzir não-linearidade na rede.\n\n2. Cálculo da Precisão:\nApós a propagação, o código calcula a precisão do modelo.\nEle compara a saída final arredondada (final_out.round()) com os valores reais de saída (y_train).\nA precisão é calculada como a proporção de acertos (acc) em relação ao tamanho total da saída (actual_out_size).\nA precisão para cada época é armazenada na lista acc_list.\n\n3. Backpropagation:\nO código então implementa o algoritmo de backpropagation para propagar o erro de volta pelas camadas.\nEle calcula o erro final (final_err) como a diferença entre a saída final e os valores reais.\nA derivada da função de ativação (derivative_hyperbolic) é usada para calcular a contribuição do erro para cada camada.\nO erro é propagado para trás, calculando o erro para cada camada oculta (l1_err, l2_err, etc.).\n\n4. Atualização dos Pesos:\nO código atualiza os pesos da rede neural usando a regra de atualização do gradiente descendente com momentum.\nPara cada camada, ele calcula o gradiente do erro em relação aos pesos correspondentes (wheight1, wheight2, etc.).\nO gradiente é dividido pelo tamanho da saída (actual_out_size) para normalizar a atualização.\nOs pesos são atualizados subtraindo o produto da taxa de aprendizado (eta), momento (alpha), e o gradiente.\n\n5. Saída e Plot da Precisão:\nApós o treinamento, o código exibe a precisão final arredondada como porcentagem.\nEle também calcula e exibe o tempo gasto no treinamento.\nPor fim, o código plota a curva de precisão ao longo das épocas usando a biblioteca matplotlib (plt).\n\nObservações:\nO código assume que as funções hyperbolic_tanh e derivative_hyperbolic estão definidas em algum lugar fora deste trecho.\nO código usa o momentum (alpha) para acelerar a convergência do treinamento.\nEste é um exemplo básico de backpropagation. Redes neurais mais complexas podem usar arquiteturas e técnicas de treinamento diferentes.\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-20T13:41:54.801178Z","iopub.execute_input":"2024-03-20T13:41:54.801673Z","iopub.status.idle":"2024-03-20T13:42:30.766984Z","shell.execute_reply.started":"2024-03-20T13:41:54.801639Z","shell.execute_reply":"2024-03-20T13:42:30.766031Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"----- Traning Backpropagation Algorithm -----\nTraning accuracy: 0.0 %\nTime traning algorithm: 35.637744 seconds \n\n----- Plotting Accuracy Curve -----\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAksAAAHHCAYAAACvJxw8AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAA350lEQVR4nO3de1hVZf7//9dGzigH5SSKx0xMHTVUxKxmksJDlomlXpZofjNNzbKcNE9NTdk0ncvDOFdpjSikqR9zzD6Elh3IA56PmaV4AjTjICoi3L8/5uee9gdcggGbbc/Hde0rudd7rf2+b6/cr2vttRY2Y4wRAAAAyuXm7AYAAABqM8ISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISAACABcISgAqbM2eObDabYmJinN2KS8rOztbTTz+tqKgo+fr6ys/PT9HR0frrX/+q3NxcZ7cH4Aps/G44ABV1yy236MSJEzp8+LAOHjyoG264wdktuYzNmzerT58+Onv2rB588EFFR0dLkrZs2aLk5GR1795d//u//+vkLgGUh7AEoEJ++ukntWjRQsuXL9ejjz6qsWPHaubMmc5uq1yFhYXy8/Nzdht2ubm5ateunS5duqQvvvhCUVFRDtuzs7P1z3/+U9OmTfvN71Xb5g5cD/gaDkCFJCUlKSgoSH379tXAgQOVlJRUbl1ubq6efPJJNWvWTF5eXmrcuLGGDRum06dP22suXLig5557TjfeeKO8vb3VsGFDDRgwQIcOHZIkffHFF7LZbPriiy8cjn348GHZbDYtXLjQPjZ8+HDVrVtXhw4dUp8+fVSvXj0NHTpUkvTVV1/p/vvvV5MmTeTl5aXIyEg9+eSTOn/+fJm+9+/frwceeEAhISHy8fFR69atNXXqVEnS+vXrZbPZtGLFijL7LV68WDabTenp6Vdcu3/84x86fvy4Xn/99TJBSZLCwsIcgpLNZtNzzz1Xpq5Zs2YaPny4/eeFCxfKZrPpyy+/1GOPPabQ0FA1btxYy5Yts4+X14vNZtPu3bsd5j5w4EDVr19f3t7e6ty5s1atWnXF+QC/N+7ObgCAa0hKStKAAQPk6empIUOGaO7cudq8ebO6dOlirzl79qxuvfVW7du3Tw8//LBuvvlmnT59WqtWrdKxY8cUHByskpIS3X333UpLS9PgwYM1YcIEFRQUKDU1Vbt371bLli0r3dulS5cUHx+vHj166NVXX5Wvr68kaenSpTp37pzGjBmjBg0aaNOmTXrnnXd07NgxLV261L7/zp07deutt8rDw0OjRo1Ss2bNdOjQIX3yySd68cUX9cc//lGRkZFKSkrSfffdV2ZdWrZsqdjY2Cv2t2rVKvn4+GjgwIGVnltFPPbYYwoJCdGMGTNUWFiovn37qm7duvroo490++23O9SmpKSobdu2ateunSRpz549uuWWW9SoUSNNnjxZfn5++uijj9S/f399/PHHZeYL/C4ZALiKLVu2GEkmNTXVGGNMaWmpady4sZkwYYJD3YwZM4wks3z58jLHKC0tNcYY8/777xtJ5vXXX79izfr1640ks379eoftP/30k5FkFixYYB9LTEw0kszkyZPLHO/cuXNlxmbNmmVsNps5cuSIfey2224z9erVcxj7dT/GGDNlyhTj5eVlcnNz7WM5OTnG3d3dzJw5s8z7/FpQUJDp0KGDZc2vSSr3mE2bNjWJiYn2nxcsWGAkmR49ephLly451A4ZMsSEhoY6jJ88edK4ubmZ559/3j7Ws2dP0759e3PhwgX7WGlpqenevbtp1apVhXsGrmd8DQfgqpKSkhQWFqY//elPkv7zNdGgQYOUnJyskpISe93HH3+sDh06lHs2wmaz2WuCg4M1fvz4K9ZcizFjxpQZ8/Hxsf+5sLBQp0+fVvfu3WWM0bZt2yRJp06d0oYNG/Twww+rSZMmV+xn2LBhKioq0rJly+xjKSkpunTpkh588EHL3vLz81WvXr1rmldFPPLII6pTp47D2KBBg5STk+PwVeayZctUWlqqQYMGSZLOnDmjdevW6YEHHlBBQYFOnz6t06dP6+eff1Z8fLwOHjyo48ePV1vfgKsgLAGwVFJSouTkZP3pT3/STz/9pB9++EE//PCDYmJilJ2drbS0NHvtoUOH7F/vXMmhQ4fUunVrubtX3VUA7u7uaty4cZnxzMxMDR8+XPXr11fdunUVEhJi/1oqLy9PkvTjjz9K0lX7joqKUpcuXRyu1UpKSlK3bt2uelegv7+/CgoKKjWnymjevHmZsV69eikgIEApKSn2sZSUFHXs2FE33nijJOmHH36QMUbTp09XSEiIw+vyxfs5OTnV1jfgKrhmCYCldevW6eTJk0pOTlZycnKZ7UlJSbrrrruq9D2vdIbp12exfs3Ly0tubm5lau+8806dOXNGzzzzjKKiouTn56fjx49r+PDhKi0trXRfw4YN04QJE3Ts2DEVFRXpu+++07vvvnvV/aKiorR9+3ZdvHhRnp6elX7fy640/1+fQbvMy8tL/fv314oVKzRnzhxlZ2frm2++0UsvvWSvubwGTz/9tOLj48s9No+HAAhLAK4iKSlJoaGhmj17dplty5cv14oVKzRv3jz5+PioZcuWDndZladly5bauHGjiouL5eHhUW5NUFCQJJV5UOORI0cq3PeuXbv0/fff64MPPtCwYcPs46mpqQ51LVq0kKSr9i1JgwcP1sSJE7VkyRKdP39eHh4e9q+0rPTr10/p6en6+OOPNWTIkKvWBwUFlZn7xYsXdfLkyavu+2uDBg3SBx98oLS0NO3bt0/GGId+L8/dw8NDcXFxlTo28HvC13AAruj8+fNavny57r77bg0cOLDMa9y4cSooKLDfZp6QkKAdO3aUe4u9+f8f6ZaQkKDTp0+Xe0bmck3Tpk1Vp04dbdiwwWH7nDlzKtz75Wt4zK8eJWeM0VtvveVQFxISottuu03vv/++MjMzy+3nsuDgYPXu3VuLFi1SUlKSevXqpeDg4Kv2Mnr0aDVs2FBPPfWUvv/++zLbc3Jy9Ne//tX+c8uWLcvMff78+Vc8s3QlcXFxql+/vlJSUpSSkqKuXbs6fGUXGhqqP/7xj/rHP/5RbhA7depUpd4PuF5xZgnAFa1atUoFBQW65557yt3erVs3hYSEKCkpSYMGDdKkSZO0bNky3X///Xr44YcVHR2tM2fOaNWqVZo3b546dOigYcOG6cMPP9TEiRO1adMm3XrrrSosLNTnn3+uxx57TPfee68CAgJ0//3365133pHNZlPLli21evXqSl0/ExUVpZYtW+rpp5/W8ePH5e/vr48//li//PJLmdq3335bPXr00M0336xRo0apefPmOnz4sP79739r+/btDrXDhg2zPwLghRdeqFAvQUFBWrFihfr06aOOHTs6PMF769atWrJkicOjB/7f//t/Gj16tBISEnTnnXdqx44d+uyzzyoUzH7Nw8NDAwYMUHJysgoLC/Xqq6+WqZk9e7Z69Oih9u3b65FHHlGLFi2UnZ2t9PR0HTt2TDt27KjUewLXJefdiAegtuvXr5/x9vY2hYWFV6wZPny48fDwMKdPnzbGGPPzzz+bcePGmUaNGhlPT0/TuHFjk5iYaN9uzH9u6Z86dapp3ry58fDwMOHh4WbgwIHm0KFD9ppTp06ZhIQE4+vra4KCgsyjjz5qdu/eXe6jA/z8/Mrtbe/evSYuLs7UrVvXBAcHm0ceecTs2LGjzDGMMWb37t3mvvvuM4GBgcbb29u0bt3aTJ8+vcwxi4qKTFBQkAkICDDnz5+vyDLanThxwjz55JPmxhtvNN7e3sbX19dER0ebF1980eTl5dnrSkpKzDPPPGOCg4ONr6+viY+PNz/88MMVHx2wefPmK75namqqkWRsNps5evRouTWHDh0yw4YNM+Hh4cbDw8M0atTI3H333WbZsmWVmh9wveLXnQBAJVy6dEkRERHq16+f3nvvPWe3A6AGcM0SAFTCypUrderUKYeLxgFc3zizBAAVsHHjRu3cuVMvvPCCgoODtXXrVme3BKCGcGYJACpg7ty5GjNmjEJDQ/Xhhx86ux0ANYgzSwAAABY4swQAAGCBsAQAAGCBh1JWgdLSUp04cUL16tX7Tb81HQAA1BxjjAoKChQREVHm90v+GmGpCpw4cUKRkZHObgMAAFyDo0ePqnHjxlfcTliqAvXq1ZP0n8X29/d3cjcAAKAi8vPzFRkZaf8cvxLCUhW4/NWbv78/YQkAABdztUtouMAbAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAAmEJAADAgsuFpdmzZ6tZs2by9vZWTEyMNm3aZFm/dOlSRUVFydvbW+3bt9eaNWuuWDt69GjZbDa9+eabVdw1AABwVS4VllJSUjRx4kTNnDlTW7duVYcOHRQfH6+cnJxy67/99lsNGTJEI0eO1LZt29S/f3/1799fu3fvLlO7YsUKfffdd4qIiKjuaQAAABfiUmHp9ddf1yOPPKIRI0bopptu0rx58+Tr66v333+/3Pq33npLvXr10qRJk9SmTRu98MILuvnmm/Xuu+861B0/flzjx49XUlKSPDw8amIqAADARbhMWLp48aIyMjIUFxdnH3Nzc1NcXJzS09PL3Sc9Pd2hXpLi4+Md6ktLS/XQQw9p0qRJatu2bfU0DwAAXJa7sxuoqNOnT6ukpERhYWEO42FhYdq/f3+5+2RlZZVbn5WVZf/5b3/7m9zd3fX4449XuJeioiIVFRXZf87Pz6/wvgAAwLW4zJml6pCRkaG33npLCxculM1mq/B+s2bNUkBAgP0VGRlZjV0CAABncpmwFBwcrDp16ig7O9thPDs7W+Hh4eXuEx4ebln/1VdfKScnR02aNJG7u7vc3d115MgRPfXUU2rWrNkVe5kyZYry8vLsr6NHj/62yQEAgFrLZcKSp6enoqOjlZaWZh8rLS1VWlqaYmNjy90nNjbWoV6SUlNT7fUPPfSQdu7cqe3bt9tfERERmjRpkj777LMr9uLl5SV/f3+HFwAAuD65zDVLkjRx4kQlJiaqc+fO6tq1q958800VFhZqxIgRkqRhw4apUaNGmjVrliRpwoQJuv322/Xaa6+pb9++Sk5O1pYtWzR//nxJUoMGDdSgQQOH9/Dw8FB4eLhat25ds5MDAAC1kkuFpUGDBunUqVOaMWOGsrKy1LFjR61du9Z+EXdmZqbc3P57sqx79+5avHixpk2bpmeffVatWrXSypUr1a5dO2dNAQAAuBibMcY4uwlXl5+fr4CAAOXl5fGVHAAALqKin98uc80SAACAMxCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALBCWAAAALLhcWJo9e7aaNWsmb29vxcTEaNOmTZb1S5cuVVRUlLy9vdW+fXutWbPGvq24uFjPPPOM2rdvLz8/P0VERGjYsGE6ceJEdU8DAAC4CJcKSykpKZo4caJmzpyprVu3qkOHDoqPj1dOTk659d9++62GDBmikSNHatu2berfv7/69++v3bt3S5LOnTunrVu3avr06dq6dauWL1+uAwcO6J577qnJaQEAgFrMZowxzm6iomJiYtSlSxe9++67kqTS0lJFRkZq/Pjxmjx5cpn6QYMGqbCwUKtXr7aPdevWTR07dtS8efPKfY/Nmzera9euOnLkiJo0aVKhvvLz8xUQEKC8vDz5+/tfw8wAAEBNq+jnt8ucWbp48aIyMjIUFxdnH3Nzc1NcXJzS09PL3Sc9Pd2hXpLi4+OvWC9JeXl5stlsCgwMrJK+AQCAa3N3dgMVdfr0aZWUlCgsLMxhPCwsTPv37y93n6ysrHLrs7Kyyq2/cOGCnnnmGQ0ZMsQyYRYVFamoqMj+c35+fkWnAQAAXIzLnFmqbsXFxXrggQdkjNHcuXMta2fNmqWAgAD7KzIysoa6BAAANc1lwlJwcLDq1Kmj7Oxsh/Hs7GyFh4eXu094eHiF6i8HpSNHjig1NfWq1x1NmTJFeXl59tfRo0evYUYAAMAVuExY8vT0VHR0tNLS0uxjpaWlSktLU2xsbLn7xMbGOtRLUmpqqkP95aB08OBBff7552rQoMFVe/Hy8pK/v7/DCwAAXJ9c5polSZo4caISExPVuXNnde3aVW+++aYKCws1YsQISdKwYcPUqFEjzZo1S5I0YcIE3X777XrttdfUt29fJScna8uWLZo/f76k/wSlgQMHauvWrVq9erVKSkrs1zPVr19fnp6ezpkoAACoNVwqLA0aNEinTp3SjBkzlJWVpY4dO2rt2rX2i7gzMzPl5vbfk2Xdu3fX4sWLNW3aND377LNq1aqVVq5cqXbt2kmSjh8/rlWrVkmSOnbs6PBe69ev1x//+McamRcAAKi9XOo5S7UVz1kCAMD1XHfPWQIAAHAGwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAIAFwhIAAICFSoelZs2a6fnnn1dmZmZ19AMAAFCrVDosPfHEE1q+fLlatGihO++8U8nJySoqKqqO3gAAAJzumsLS9u3btWnTJrVp00bjx49Xw4YNNW7cOG3durU6egQAAHAamzHG/JYDFBcXa86cOXrmmWdUXFys9u3b6/HHH9eIESNks9mqqs9aLT8/XwEBAcrLy5O/v7+z2wEAABVQ0c9v92t9g+LiYq1YsUILFixQamqqunXrppEjR+rYsWN69tln9fnnn2vx4sXXengAAIBaodJhaevWrVqwYIGWLFkiNzc3DRs2TG+88YaioqLsNffdd5+6dOlSpY0CAAA4Q6XDUpcuXXTnnXdq7ty56t+/vzw8PMrUNG/eXIMHD66SBgEAAJyp0mHpxx9/VNOmTS1r/Pz8tGDBgmtuCgAAoLao9N1wOTk52rhxY5nxjRs3asuWLVXSFAAAQG1R6bA0duxYHT16tMz48ePHNXbs2CppCgAAoLaodFjau3evbr755jLjnTp10t69e6ukKQAAgNqi0mHJy8tL2dnZZcZPnjwpd/drfhIBAABArVTpsHTXXXdpypQpysvLs4/l5ubq2Wef1Z133lmlzQEAADhbpU8Fvfrqq7rtttvUtGlTderUSZK0fft2hYWF6V//+leVNwgAAOBMlQ5LjRo10s6dO5WUlKQdO3bIx8dHI0aM0JAhQ8p95hIAAIAru6aLjPz8/DRq1Kiq7gUAAKDWueYrsvfu3avMzExdvHjRYfyee+75zU0BAADUFtf0BO/77rtPu3btks1mkzFGkmSz2SRJJSUlVdshAACAE1X6brgJEyaoefPmysnJka+vr/bs2aMNGzaoc+fO+uKLL6qhRQAAAOep9Jml9PR0rVu3TsHBwXJzc5Obm5t69OihWbNm6fHHH9e2bduqo08AAACnqPSZpZKSEtWrV0+SFBwcrBMnTkiSmjZtqgMHDlRtdwAAAE5W6TNL7dq1044dO9S8eXPFxMTolVdekaenp+bPn68WLVpUR48AAABOU+mwNG3aNBUWFkqSnn/+ed1999269dZb1aBBA6WkpFR5gwAAAM5kM5dvZ/sNzpw5o6CgIPsdcb83+fn5CggIUF5envz9/Z3dDgAAqICKfn5X6pql4uJiubu7a/fu3Q7j9evX/90GJQAAcH2rVFjy8PBQkyZNnPospdmzZ6tZs2by9vZWTEyMNm3aZFm/dOlSRUVFydvbW+3bt9eaNWscthtjNGPGDDVs2FA+Pj6Ki4vTwYMHq3MKAADAhVT6bripU6fq2Wef1ZkzZ6qjH0spKSmaOHGiZs6cqa1bt6pDhw6Kj49XTk5OufXffvuthgwZopEjR2rbtm3q37+/+vfv73Bm7JVXXtHbb7+tefPmaePGjfLz81N8fLwuXLhQU9MCAAC1WKWvWerUqZN++OEHFRcXq2nTpvLz83PYvnXr1ipt8NdiYmLUpUsXvfvuu5Kk0tJSRUZGavz48Zo8eXKZ+kGDBqmwsFCrV6+2j3Xr1k0dO3bUvHnzZIxRRESEnnrqKT399NOSpLy8PIWFhWnhwoUaPHhwhfqqrmuWjv1yrsqOBQCAK2sU6FPll/xU9PO70nfD9e/f/7f0dc0uXryojIwMTZkyxT7m5uamuLg4paenl7tPenq6Jk6c6DAWHx+vlStXSpJ++uknZWVlKS4uzr49ICBAMTExSk9Pv2JYKioqUlFRkf3n/Pz8a52WpTte+1IXL5VWy7EBAHAl3/+1tzzdnXN9dKXD0syZM6ujj6s6ffq0SkpKFBYW5jAeFham/fv3l7tPVlZWufVZWVn27ZfHrlRTnlmzZukvf/lLpedQWV7ubuKyeQAAnKvSYQnSlClTHM5Y5efnKzIyssrfZ9dz8VV+TAAAUDmVDktubm6W3xlW151ywcHBqlOnjrKzsx3Gs7OzFR4eXu4+4eHhlvWX/5udna2GDRs61HTs2PGKvXh5ecnLy+tapgEAAFxMpe+GW7FihZYvX25/paSkaPLkyWrYsKHmz59fHT1Kkjw9PRUdHa20tDT7WGlpqdLS0hQbG1vuPrGxsQ71kpSammqvb968ucLDwx1q8vPztXHjxiseEwAA/L5U+szSvffeW2Zs4MCBatu2rVJSUjRy5Mgqaaw8EydOVGJiojp37qyuXbvqzTffVGFhoUaMGCFJGjZsmBo1aqRZs2ZJkiZMmKDbb79dr732mvr27avk5GRt2bLFHupsNpueeOIJ/fWvf1WrVq3UvHlzTZ8+XREREU67kB0AANQuVXbNUrdu3TRq1KiqOly5Bg0apFOnTmnGjBnKyspSx44dtXbtWvsF2pmZmXJz++/Jsu7du2vx4sWaNm2ann32WbVq1UorV65Uu3bt7DV//vOfVVhYqFGjRik3N1c9evTQ2rVr5e3tXa1zAQAArqFKfjfc+fPnNWXKFH366ac6cOBAVfTlUvjdcAAAuJ5qe87S//2FucYYFRQUyNfXV4sWLbq2bgEAAGqpSoelN954wyEsubm5KSQkRDExMQoKCqrS5gAAAJyt0mFp+PDh1dAGAABA7VTpRwcsWLBAS5cuLTO+dOlSffDBB1XSFAAAQG1R6bA0a9YsBQcHlxkPDQ3VSy+9VCVNAQAA1BaVDkuZmZlq3rx5mfGmTZsqMzOzSpoCAACoLSodlkJDQ7Vz584y4zt27FCDBg2qpCkAAIDaotJhaciQIXr88ce1fv16lZSUqKSkROvWrdOECRM0ePDg6ugRAADAaSp9N9wLL7ygw4cPq2fPnnJ3/8/upaWlGjZsGNcsAQCA6841P8H74MGD2r59u3x8fNS+fXs1bdq0qntzGTzBGwAA11NtT/C+rFWrVmrVqtW17g4AAOASKn3NUkJCgv72t7+VGX/llVd0//33V0lTAAAAtUWlw9KGDRvUp0+fMuO9e/fWhg0bqqQpAACA2qLSYens2bPy9PQsM+7h4aH8/PwqaQoAAKC2qHRYat++vVJSUsqMJycn66abbqqSpgAAAGqLSl/gPX36dA0YMECHDh3SHXfcIUlKS0vT4sWLtWzZsipvEAAAwJkqHZb69eunlStX6qWXXtKyZcvk4+OjDh06aN26dapfv3519AgAAOA01/ycpcvy8/O1ZMkSvffee8rIyFBJSUlV9eYyeM4SAACup6Kf35W+ZumyDRs2KDExUREREXrttdd0xx136LvvvrvWwwEAANRKlfoaLisrSwsXLtR7772n/Px8PfDAAyoqKtLKlSu5uBsAAFyXKnxmqV+/fmrdurV27typN998UydOnNA777xTnb0BAAA4XYXPLH366ad6/PHHNWbMGH7NCQAA+N2o8Jmlr7/+WgUFBYqOjlZMTIzeffddnT59ujp7AwAAcLoKh6Vu3brpn//8p06ePKlHH31UycnJioiIUGlpqVJTU1VQUFCdfQIAADjFb3p0wIEDB/Tee+/pX//6l3Jzc3XnnXdq1apVVdmfS+DRAQAAuJ5qf3SAJLVu3VqvvPKKjh07piVLlvyWQwEAANRKv/mhlODMEgAArqhGziwBAABc7whLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFghLAAAAFlwmLJ05c0ZDhw6Vv7+/AgMDNXLkSJ09e9ZynwsXLmjs2LFq0KCB6tatq4SEBGVnZ9u379ixQ0OGDFFkZKR8fHzUpk0bvfXWW9U9FQAA4EJcJiwNHTpUe/bsUWpqqlavXq0NGzZo1KhRlvs8+eST+uSTT7R06VJ9+eWXOnHihAYMGGDfnpGRodDQUC1atEh79uzR1KlTNWXKFL377rvVPR0AAOAibMYY4+wmrmbfvn266aabtHnzZnXu3FmStHbtWvXp00fHjh1TREREmX3y8vIUEhKixYsXa+DAgZKk/fv3q02bNkpPT1e3bt3Kfa+xY8dq3759WrduXYX7y8/PV0BAgPLy8uTv738NMwQAADWtop/fLnFmKT09XYGBgfagJElxcXFyc3PTxo0by90nIyNDxcXFiouLs49FRUWpSZMmSk9Pv+J75eXlqX79+pb9FBUVKT8/3+EFAACuTy4RlrKyshQaGuow5u7urvr16ysrK+uK+3h6eiowMNBhPCws7Ir7fPvtt0pJSbnq13uzZs1SQECA/RUZGVnxyQAAAJfi1LA0efJk2Ww2y9f+/ftrpJfdu3fr3nvv1cyZM3XXXXdZ1k6ZMkV5eXn219GjR2ukRwAAUPPcnfnmTz31lIYPH25Z06JFC4WHhysnJ8dh/NKlSzpz5ozCw8PL3S88PFwXL15Ubm6uw9ml7OzsMvvs3btXPXv21KhRozRt2rSr9u3l5SUvL6+r1gEAANfn1LAUEhKikJCQq9bFxsYqNzdXGRkZio6OliStW7dOpaWliomJKXef6OhoeXh4KC0tTQkJCZKkAwcOKDMzU7Gxsfa6PXv26I477lBiYqJefPHFKpgVAAC4nrjE3XCS1Lt3b2VnZ2vevHkqLi7WiBEj1LlzZy1evFiSdPz4cfXs2VMffvihunbtKkkaM2aM1qxZo4ULF8rf31/jx4+X9J9rk6T/fPV2xx13KD4+Xn//+9/t71WnTp0KhbjLuBsOAADXU9HPb6eeWaqMpKQkjRs3Tj179pSbm5sSEhL09ttv27cXFxfrwIEDOnfunH3sjTfesNcWFRUpPj5ec+bMsW9ftmyZTp06pUWLFmnRokX28aZNm+rw4cM1Mi8AAFC7ucyZpdqMM0sAALie6+o5SwAAAM5CWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALBAWAIAALDgMmHpzJkzGjp0qPz9/RUYGKiRI0fq7NmzlvtcuHBBY8eOVYMGDVS3bl0lJCQoOzu73Nqff/5ZjRs3ls1mU25ubjXMAAAAuCKXCUtDhw7Vnj17lJqaqtWrV2vDhg0aNWqU5T5PPvmkPvnkEy1dulRffvmlTpw4oQEDBpRbO3LkSP3hD3+ojtYBAIALsxljjLObuJp9+/bppptu0ubNm9W5c2dJ0tq1a9WnTx8dO3ZMERERZfbJy8tTSEiIFi9erIEDB0qS9u/frzZt2ig9PV3dunWz186dO1cpKSmaMWOGevbsqV9++UWBgYEV7i8/P18BAQHKy8uTv7//b5ssAACoERX9/HaJM0vp6ekKDAy0ByVJiouLk5ubmzZu3FjuPhkZGSouLlZcXJx9LCoqSk2aNFF6erp9bO/evXr++ef14Ycfys2tYstRVFSk/Px8hxcAALg+uURYysrKUmhoqMOYu7u76tevr6ysrCvu4+npWeYMUVhYmH2foqIiDRkyRH//+9/VpEmTCvcza9YsBQQE2F+RkZGVmxAAAHAZTg1LkydPls1ms3zt37+/2t5/ypQpatOmjR588MFK75eXl2d/HT16tJo6BAAAzubuzDd/6qmnNHz4cMuaFi1aKDw8XDk5OQ7jly5d0pkzZxQeHl7ufuHh4bp48aJyc3Mdzi5lZ2fb91m3bp127dqlZcuWSZIuX74VHBysqVOn6i9/+Uu5x/by8pKXl1dFpggAAFycU8NSSEiIQkJCrloXGxur3NxcZWRkKDo6WtJ/gk5paaliYmLK3Sc6OloeHh5KS0tTQkKCJOnAgQPKzMxUbGysJOnjjz/W+fPn7fts3rxZDz/8sL766iu1bNnyt04PAABcB5waliqqTZs26tWrlx555BHNmzdPxcXFGjdunAYPHmy/E+748ePq2bOnPvzwQ3Xt2lUBAQEaOXKkJk6cqPr168vf31/jx49XbGys/U64/xuITp8+bX+/ytwNBwAArl8uEZYkKSkpSePGjVPPnj3l5uamhIQEvf322/btxcXFOnDggM6dO2cfe+ONN+y1RUVFio+P15w5c5zRPgAAcFEu8Zyl2o7nLAEA4Hquq+csAQAAOAthCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwAJhCQAAwIK7sxu4HhhjJEn5+flO7gQAAFTU5c/ty5/jV0JYqgIFBQWSpMjISCd3AgAAKqugoEABAQFX3G4zV4tTuKrS0lKdOHFC9erVk81mq7Lj5ufnKzIyUkePHpW/v3+VHReOWOeawTrXHNa6ZrDONaM619kYo4KCAkVERMjN7cpXJnFmqQq4ubmpcePG1XZ8f39//kesAaxzzWCdaw5rXTNY55pRXetsdUbpMi7wBgAAsEBYAgAAsEBYqsW8vLw0c+ZMeXl5ObuV6xrrXDNY55rDWtcM1rlm1IZ15gJvAAAAC5xZAgAAsEBYAgAAsEBYAgAAsEBYAgAAsEBYqsVmz56tZs2aydvbWzExMdq0aZOzW6q1Zs2apS5duqhevXoKDQ1V//79deDAAYeaCxcuaOzYsWrQoIHq1q2rhIQEZWdnO9RkZmaqb9++8vX1VWhoqCZNmqRLly451HzxxRe6+eab5eXlpRtuuEELFy6s7unVWi+//LJsNpueeOIJ+xjrXDWOHz+uBx98UA0aNJCPj4/at2+vLVu22LcbYzRjxgw1bNhQPj4+iouL08GDBx2OcebMGQ0dOlT+/v4KDAzUyJEjdfbsWYeanTt36tZbb5W3t7ciIyP1yiuv1Mj8aoOSkhJNnz5dzZs3l4+Pj1q2bKkXXnjB4feEsc7XZsOGDerXr58iIiJks9m0cuVKh+01ua5Lly5VVFSUvL291b59e61Zs6byEzKolZKTk42np6d5//33zZ49e8wjjzxiAgMDTXZ2trNbq5Xi4+PNggULzO7du8327dtNnz59TJMmTczZs2ftNaNHjzaRkZEmLS3NbNmyxXTr1s10797dvv3SpUumXbt2Ji4uzmzbts2sWbPGBAcHmylTpthrfvzxR+Pr62smTpxo9u7da9555x1Tp04ds3bt2hqdb22wadMm06xZM/OHP/zBTJgwwT7OOv92Z86cMU2bNjXDhw83GzduND/++KP57LPPzA8//GCvefnll01AQIBZuXKl2bFjh7nnnntM8+bNzfnz5+01vXr1Mh06dDDfffed+eqrr8wNN9xghgwZYt+el5dnwsLCzNChQ83u3bvNkiVLjI+Pj/nHP/5Ro/N1lhdffNE0aNDArF692vz0009m6dKlpm7duuatt96y17DO12bNmjVm6tSpZvny5UaSWbFihcP2mlrXb775xtSpU8e88sorZu/evWbatGnGw8PD7Nq1q1LzISzVUl27djVjx461/1xSUmIiIiLMrFmznNiV68jJyTGSzJdffmmMMSY3N9d4eHiYpUuX2mv27dtnJJn09HRjzH/+53ZzczNZWVn2mrlz5xp/f39TVFRkjDHmz3/+s2nbtq3Dew0aNMjEx8dX95RqlYKCAtOqVSuTmppqbr/9dntYYp2rxjPPPGN69Ohxxe2lpaUmPDzc/P3vf7eP5ebmGi8vL7NkyRJjjDF79+41kszmzZvtNZ9++qmx2Wzm+PHjxhhj5syZY4KCguzrfvm9W7duXdVTqpX69u1rHn74YYexAQMGmKFDhxpjWOeq8n/DUk2u6wMPPGD69u3r0E9MTIx59NFHKzUHvoarhS5evKiMjAzFxcXZx9zc3BQXF6f09HQnduY68vLyJEn169eXJGVkZKi4uNhhTaOiotSkSRP7mqanp6t9+/YKCwuz18THxys/P1979uyx1/z6GJdrfm9/L2PHjlXfvn3LrAXrXDVWrVqlzp076/7771doaKg6deqkf/7zn/btP/30k7KyshzWKCAgQDExMQ7rHBgYqM6dO9tr4uLi5Obmpo0bN9prbrvtNnl6etpr4uPjdeDAAf3yyy/VPU2n6969u9LS0vT9999Lknbs2KGvv/5avXv3lsQ6V5eaXNeq+reEsFQLnT59WiUlJQ4fJpIUFhamrKwsJ3XlOkpLS/XEE0/olltuUbt27SRJWVlZ8vT0VGBgoEPtr9c0Kyur3DW/vM2qJj8/X+fPn6+O6dQ6ycnJ2rp1q2bNmlVmG+tcNX788UfNnTtXrVq10meffaYxY8bo8ccf1wcffCDpv+tk9W9EVlaWQkNDHba7u7urfv36lfq7uJ5NnjxZgwcPVlRUlDw8PNSpUyc98cQTGjp0qCTWubrU5Lpeqaay6+5eqWrABYwdO1a7d+/W119/7exWrjtHjx7VhAkTlJqaKm9vb2e3c90qLS1V586d9dJLL0mSOnXqpN27d2vevHlKTEx0cnfXj48++khJSUlavHix2rZtq+3bt+uJJ55QREQE6wwHnFmqhYKDg1WnTp0ydxBlZ2crPDzcSV25hnHjxmn16tVav369GjdubB8PDw/XxYsXlZub61D/6zUNDw8vd80vb7Oq8ff3l4+PT1VPp9bJyMhQTk6Obr75Zrm7u8vd3V1ffvml3n77bbm7uyssLIx1rgINGzbUTTfd5DDWpk0bZWZmSvrvOln9GxEeHq6cnByH7ZcuXdKZM2cq9XdxPZs0aZL97FL79u310EMP6cknn7SfNWWdq0dNruuVaiq77oSlWsjT01PR0dFKS0uzj5WWliotLU2xsbFO7Kz2MsZo3LhxWrFihdatW6fmzZs7bI+OjpaHh4fDmh44cECZmZn2NY2NjdWuXbsc/gdNTU2Vv7+//YMrNjbW4RiXa34vfy89e/bUrl27tH37dvurc+fOGjp0qP3PrPNvd8stt5R59MX333+vpk2bSpKaN2+u8PBwhzXKz8/Xxo0bHdY5NzdXGRkZ9pp169aptLRUMTEx9poNGzaouLjYXpOamqrWrVsrKCio2uZXW5w7d05ubo4fg3Xq1FFpaakk1rm61OS6Vtm/JZW6HBw1Jjk52Xh5eZmFCxeavXv3mlGjRpnAwECHO4jwX2PGjDEBAQHmiy++MCdPnrS/zp07Z68ZPXq0adKkiVm3bp3ZsmWLiY2NNbGxsfbtl29pv+uuu8z27dvN2rVrTUhISLm3tE+aNMns27fPzJ49+3d1S3t5fn03nDGsc1XYtGmTcXd3Ny+++KI5ePCgSUpKMr6+vmbRokX2mpdfftkEBgaa//mf/zE7d+409957b7m3Xnfq1Mls3LjRfP3116ZVq1YOt17n5uaasLAw89BDD5ndu3eb5ORk4+vre13f0v5riYmJplGjRvZHByxfvtwEBwebP//5z/Ya1vnaFBQUmG3btplt27YZSeb1118327ZtM0eOHDHG1Ny6fvPNN8bd3d28+uqrZt++fWbmzJk8OuB6884775gmTZoYT09P07VrV/Pdd985u6VaS1K5rwULFthrzp8/bx577DETFBRkfH19zX333WdOnjzpcJzDhw+b3r17Gx8fHxMcHGyeeuopU1xc7FCzfv1607FjR+Pp6WlatGjh8B6/R/83LLHOVeOTTz4x7dq1M15eXiYqKsrMnz/fYXtpaamZPn26CQsLM15eXqZnz57mwIEDDjU///yzGTJkiKlbt67x9/c3I0aMMAUFBQ41O3bsMD169DBeXl6mUaNG5uWXX672udUW+fn5ZsKECaZJkybG29vbtGjRwkydOtXhVnTW+dqsX7++3H+TExMTjTE1u64fffSRufHGG42np6dp27at+fe//13p+diM+dWjSgEAAOCAa5YAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAAAAsEJYAoArYbDatXLnS2W0AqAaEJQAub/jw4bLZbGVevXr1cnZrAK4D7s5uAACqQq9evbRgwQKHMS8vLyd1A+B6wpklANcFLy8vhYeHO7wu/+Zxm82muXPnqnfv3vLx8VGLFi20bNkyh/137dqlO+64Qz4+PmrQoIFGjRqls2fPOtS8//77atu2rby8vNSwYUONGzfOYfvp06d13333ydfXV61atdKqVavs23755RcNHTpUISEh8vHxUatWrcqEOwC1E2EJwO/C9OnTlZCQoB07dmjo0KEaPHiw9u3bJ0kqLCxUfHy8goKCtHnzZi1dulSff/65QxiaO3euxo4dq1GjRmnXrl1atWqVbrjhBof3+Mtf/qIHHnhAO3fuVJ8+fTR06FCdOXPG/v579+7Vp59+qn379mnu3LkKDg6uuQUAcO0q/at3AaCWSUxMNHXq1DF+fn4OrxdffNEYY4wkM3r0aId9YmJizJgxY4wxxsyfP98EBQWZs2fP2rf/+9//Nm5ubiYrK8sYY0xERISZOnXqFXuQZKZNm2b/+ezZs0aS+fTTT40xxvTr18+MGDGiaiYMoEZxzRKA68Kf/vQnzZ0712Gsfv369j/HxsY6bIuNjdX27dslSfv27VOHDh3k5+dn337LLbeotLRUBw4ckM1m04kTJ9SzZ0/LHv7whz/Y/+zn5yd/f3/l5ORIksaMGaOEhARt3bpVd911l/r376/u3btf01wB1CzCEoDrgp+fX5mvxaqKj49Pheo8PDwcfrbZbCotLZUk9e7dW0eOHNGaNWuUmpqqnj17auzYsXr11VervF8AVYtrlgD8Lnz33Xdlfm7Tpo0kqU2bNtqxY4cKCwvt27/55hu5ubmpdevWqlevnpo1a6a0tLTf1ENISIgSExO1aNEivfnmm5o/f/5vOh6AmsGZJQDXhaKiImVlZTmMubu72y+iXrp0qTp37qwePXooKSlJmzZt0nvvvSdJGjp0qGbOnKnExEQ999xzOnXqlMaPH6+HHnpIYWFhkqTnnntOo0ePVmhoqHr37q2CggJ98803Gj9+fIX6mzFjhqKjo9W2bVsVFRVp9erV9rAGoHYjLAG4Lqxdu1YNGzZ0GGvdurX2798v6T93qiUnJ+uxxx5Tw4YNtWTJEt10002SJF9fX3322WeaMGGCunTpIl9fXyUkJOj111+3HysxMVEXLlzQG2+8oaefflrBwcEaOHBghfvz9PTUlClTdPjwYfn4+OjWW29VcnJyFcwcQHWzGWOMs5sAgOpks9m0YsUK9e/f39mtAHBBXLMEAABggbAEAABggWuWAFz3uNoAwG/BmSUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAALhCUAAAAL/x/e4WzBRTH5CwAAAABJRU5ErkJggg=="},"metadata":{}}]},{"cell_type":"code","source":"# testing backpropagation algh\nprint('----- Testing Backpropagation Algorithm -----')\nstart_time = time.time()\n\n# feedforward for 4 hidden layers by calling activation func\nl1_test = np.dot(x_test, w1_l1)\nl1_out_test = hyperbolic_tanh(l1_test)\n\nl2_test = np.dot(l1_out_test, w2_l2)\nl2_out_test = hyperbolic_tanh(l2_test)\n\nl3_test = np.dot(l2_out_test, w3_l3)\nl3_out_test = hyperbolic_tanh(l3_test)\n\nl4_test = np.dot(l3_out_test, w4_l4)\nl4_out_test = hyperbolic_tanh(l4_test)\n\noutput_test = np.dot(l4_out_test, out_w)\nfinal_out_test = hyperbolic_tanh(output_test)\n'''\no bloco acima olha a saída de cada nivel e peso e repropagando o erro para calcular o \npeso de cada camada\n'''\n\n#calcula acuracia\nactual_out_size = y_test.size\nfinal_out_test_acc = final_out_test.round()\ncalc_acc = (final_out_test_acc == y_test).sum()\nacc_test = (calc_acc / actual_out_size) * 100\n'''\no bloco acima calcula o quanto o modelo acertou\n'''\n\nprint('Testing accuracy: ' + str(round(acc_test, 2)) + ' %')\nend_time = time.time()\ntotal_time = end_time - start_time\nprint('Time testing algorithm: %f seconds \\n' % total_time)\n\n#print(final_out_test)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"'''\nResultados encontrados aq foram diferentes dos que foram apresentados na aula da Faculade Desconplica\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-20T17:45:08.471315Z","iopub.execute_input":"2024-03-20T17:45:08.472061Z","iopub.status.idle":"2024-03-20T17:45:08.517505Z","shell.execute_reply.started":"2024-03-20T17:45:08.472017Z","shell.execute_reply":"2024-03-20T17:45:08.516239Z"},"trusted":true},"execution_count":1,"outputs":[{"execution_count":1,"output_type":"execute_result","data":{"text/plain":"'\\nResultados encontrados aq foram diferentes dos que foram apresentados na aula da Faculade Desconplica\\n'"},"metadata":{}}]}]}